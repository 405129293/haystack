[bdist_wheel]
universal = 1

[metadata]
name = farm-haystack
version = file: VERSION.txt
url = https://github.com/deepset-ai/haystack,
project_urls =
    Docs: RTD = https://haystack.deepset.ai/overview/intro
    CI: GitHub = https://github.com/deepset-ai/haystack/actions
    GitHub: issues = https://github.com/deepset-ai/haystack/issues
    GitHub: repo = https://github.com/deepset-ai/haystack
description = Neural Question Answering & Semantic Search at Scale. Use modern transformer based models like BERT to find answers in large document collections
long_description = file: README.md
long_description_content_type = text/markdown
keywords=QA Question-Answering Reader Retriever semantic-search search BERT roberta albert squad mrc transfer-learning language-model transformer
author = Malte Pietsch, Timo Moeller, Branden Chan, Tanay Soni
author_email = malte.pietsch@deepset.ai
license_file = LICENSE
platforms = any
license = Apache License 2.0
classifiers =
    Development Status :: 5 - Production/Stable
    Intended Audience :: Science/Research
    License :: Freely Distributable
    License :: OSI Approved :: Apache Software License
    Topic :: Scientific/Engineering :: Artificial Intelligence
    Operating System :: OS Independent
    Programming Language :: Python
    Programming Language :: Python :: 3
    Programming Language :: Python :: 3.7
    Programming Language :: Python :: 3.8
    Programming Language :: Python :: 3.9
    Programming Language :: Python :: 3.10

[options]
use_scm_version = True
python_requires = >=3.7
packages = find:
include_package_data = True
install_requires =
    importlib-metadata; python_version < '3.8'
    torch>1.9,<1.11  # pytorch
    tqdm  # progress bars in model download and training scripts
    requests  # Used for downloading models over HTTP
    pydantic  # Validation of the core dataclasses (Document, Label, etc...)
    scipy>=1.3.2  # for stats in run_classifier
    scikit-learn>=1.0.0  # for stats in run_classifier
    seqeval  # Metrics or logging related
    mlflow<=1.13.1  # Metrics or logging related
    transformers==4.13.0  # huggingface transformers
    dill  # pickle extension for (de-)serialization
    #onnxruntime  # Inference with ONNX models. Install onnxruntime-gpu for Inference on GPUs
    #onnxruntime_tools  # Inference with ONNX models. Install onnxruntime-gpu for Inference on GPUs
    psutil
    pandas
    langdetect   # for PDF conversions
    pytesseract==0.3.7  # for PDF conversions using OCR
    pillow==8.3.2  # for PDF conversions using OCR
    pdf2image==1.14.0  # for PDF conversions using OCR
    sentence-transformers>=0.4.0
    python-multipart
    python-docx  # To read DOCX files
    tika
    uvloop==0.14; sys_platform != 'win32' and sys_platform != 'cygwin'
    httptools
    nltk
    more_itertools
    networkx
    #selenium  # For crawling
    #webdriver-manager  # For crawling
    mmh3
    dataclasses-json
    quantulum3
    azure-ai-formrecognizer==3.2.0b2

[options.extras_require]
elasticsearch=
    elasticsearch>=7.7,<=7.10
    elastic-apm
sql = 
    sqlalchemy>=1.4.2
    sqlalchemy_utils
    psycopg2-binary; sys_platform != 'win32' and sys_platform != 'cygwin'
faiss = 
    farm-haystack[sql]
    faiss-cpu>=1.6.3  # for FAISS wionth GPUs: install faiss-gpu
milvus = 
    farm-haystack[sql]
    pymilvus  # Refer milvus version support matrix at https://github.com/milvus-io/pymilvus#install-pymilvus
milvus2 = 
    farm-haystack[sql]
    pymilvus==2.0.0rc6  # Refer milvus version support matrix at https://github.com/milvus-io/pymilvus#install-pymilvus
weaviate =
    weaviate-client==2.5.0
graphdb = 
    SPARQLWrapper
docstores =
    farm-haystack[elasticsearch,faiss,milvus,weaviate,graphdb]
gpu =
    onnxruntime-gpu
    faiss-gpu
ray = 
    ray>=1.9.1
colab = 
    grpcio>=1.42.0
    pillow==7.1.3
rest =
    fastapi
    uvicorn
    gunicorn
ui = 
    streamlit>=1.2.0
    st-annotated-text==2.0.0
    markdown>=3.3.4
dev = 
    mypy
    pytest
    selenium
    webdriver-manager
    beautifulsoup4
    markdown
    tox
    coverage
ci =
    farm-haystack[docstores,rest,ui,dev]
all =
    farm-haystack[gpu,docstores,ray,rest,ui,dev]


[pytest]
testpaths = test
python_files =
    test_*.py
addopts =
    -vv


[mypy]
ignore_missing_imports = True
plugins = pydantic.mypy


[tox]
requires = tox-venv
           setuptools >= 30.0.0
envlist = py36,py37


[testenv]
changedir = test
deps =
    coverage
    pytest
    pandas
setenv =
    COVERAGE_FILE = test-reports/.coverage
    PYTEST_ADDOPTS = --junitxml=test-reports/{envname}/junit.xml -vv
commands =
    coverage run --source haystack --parallel-mode -m pytest {posargs}
    coverage combine
    coverage report -m
    coverage html -d test-reports/coverage-html
    coverage xml -o test-reports/coverage.xml
