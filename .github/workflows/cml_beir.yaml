name: benchmarks

on:
  workflow_dispatch:
  pull_request:
    types:
    - labeled
jobs:
  deploy-runner:
    if: ${{ (github.event.action == 'labeled' && github.event.label.name == 'action:benchmark_beir') || github.event.action == 'workflow_dispatch' }}
    runs-on: ubuntu-latest
    steps:
      - uses: iterative/setup-cml@v1
      - uses: actions/checkout@v2
      - name: Deploy runner on EC2
        env:
          repo_token: ${{ secrets.HAYSTACK_BOT_TOKEN }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_CI_ACCESS_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_CI_SECRET_ACCESS_KEY }}
        run: |
          cml runner \
              --cloud=aws \
              --cloud-region=us-east-1 \
              --cloud-type=p3.2xlarge \
              --labels=cml-runner \
              --idle-timeout=2400 \
              --reuse
  run-beir-benchmark:
    needs: deploy-runner
    runs-on: [ self-hosted,cml-runner ]
#    container: docker://iterativeai/cml:0-dvc2-base1
    container:
      image: docker://iterativeai/cml:0-dvc2-base1-gpu
      options: --gpus all
    steps:
      - uses: actions/checkout@v2
      - name: Run benchmark
        env:
          repo_token: ${{ secrets.HAYSTACK_BOT_TOKEN }}
        run: |
          pip install . 
          pip install beir>=0.2.3
          # install ES
          wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.9.2-linux-x86_64.tar.gz -q
          tar -xzf elasticsearch-7.9.2-linux-x86_64.tar.gz
          chown -R daemon:daemon elasticsearch-7.9.2
          # Run benchmarks
          cd test/benchmarks/beir
          python run_beir_haystack_evaluation.py
          cml send-comment report.md


