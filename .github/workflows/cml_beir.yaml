name: benchmarks

on:
  workflow_dispatch:
  pull_request:
    types:
    - labeled
    - synchronize
jobs:
  deploy-runner:
    #if: ${{ (github.event.action == 'labeled' && github.event.label.name == 'action:benchmark_beir') || github.event.action == 'workflow_dispatch' }}
    runs-on: ubuntu-latest
    steps:
      - uses: iterative/setup-cml@v1
      - uses: actions/checkout@v2
      - name: Deploy runner on EC2
        env:
          repo_token: ${{ secrets.HAYSTACK_BOT_TOKEN }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_CI_ACCESS_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_CI_SECRET_ACCESS_KEY }}
        run: |
          cml runner \
              --cloud=aws \
              --cloud-region=us-east-1 \
              --cloud-type=t3.xlarge \
              --labels=cml-runner \
              --idle-timeout=2400 \
              --reuse
  run-beir-benchmark:
    needs: deploy-runner
    runs-on: [ self-hosted,cml-runner ]
    container: docker://iterativeai/cml:0-dvc2-base1
    steps:
      - uses: actions/checkout@v2
      - name: Run benchmark
        env:
          repo_token: ${{ secrets.HAYSTACK_BOT_TOKEN }}
        run: |
          apt-get update -y
          apt-get install python3-dev -y
          pip install . 
          pip install beir>=0.2.3
          cd test/benchmarks/beir
          python run_beir_haystack_evaluation.py
          #echo "Some test from CML" >> report.md
          cml send-comment report.md


